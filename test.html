<p data-vmark="17bb"><strong>刚刚，一位 AI 公司 CEO 细细扒皮了关于 Llama 4 的五大疑点。甚至有圈内人表示，Llama 4 证明 Scaling 已经结束了，LLM 并不能可靠推理。但更可怕的事，就是全球的 AI 进步恐将彻底停滞。</strong></p><p data-vmark="9cef" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/1da1cfa8-4ad9-4947-94f1-15a316f6452d.jpg?x-bce-process=image/format,f_auto" w="1080" h="461" data-weibo="0" data-s="300,640" data-type="jpeg" data-vmark="ea54"></p><p data-vmark="880d">令人失望的 Llama 4，只是前奏而已。接下来我们恐将看到 —— 全球局势的改变，将彻底阻止 AI 进步！Anthropic CEO Dario 做出长视频，逐级对 Llama 4 身上的六大疑点进行了扒皮。</p><p data-vmark="4c38" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/44717c18-778a-43d8-99a1-95476d07aa91.png?x-bce-process=image/format,f_auto" w="1080" h="755" data-weibo="1" data-type="png" data-vmark="a390"></p><p data-vmark="f8d9">同时，纽约大学教授马库斯发出博客，总结了目前这段时间 AI 圈的状况。</p><blockquote><p data-vmark="b98b">Scaling 已经结束；模型仍然无法可靠推理；金融泡沫正在破裂；依然没有 GPT-5；对不可靠的语言模型的过度依赖让世界陷入了困境。我的 25 个 2025 年预测中的每一个，目前看起来都是对的。</p><p data-vmark="0a91">大语言模型不是解决之道。我们确实需要一些更可靠的方法。</p></blockquote><p data-vmark="1eaf">OpenAI 和 Anthropic 这样的公司，需要筹集资金来资助新模型本后的大规模训练运行，但他们的银行账户里并没有 400 亿或 1000 亿美元，来支撑庞大的数据中心和其他费用。</p><p data-vmark="923b">问题在于，如果投资者预见到了经济衰退，那就要么不会投资，要么投资较少。</p><p data-vmark="74a7">更少的资金，就意味着更少的计算，也就是更慢的 AI 进展。</p><p data-vmark="f045">布鲁金斯学会 2025 年的一份报告称，若科研成本持续上升，美国在人工智能、生物技术和量子计算等关键领域的领先地位可能受到威胁。据估算，当前政策若持续实施五年，美国科研产出可能会下降 8%-12%。</p><p data-vmark="31a8">在以前的一个采访里，Anthropic CEO Dario 曾被问到：到了如今这个阶段，还有什么可以阻止 AI 的进步？他提到了一种可能 —— 战争。</p><p data-vmark="5a21" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/74b96a2a-1500-46ad-b69a-7c649dd3e7b0.png?x-bce-process=image/format,f_auto" w="1080" h="599" data-weibo="2" data-type="png" data-vmark="689c"></p><p data-vmark="dfee">没想到，在这个可能性之外，我们居然提前见证了系统的另一种混沌。</p><p data-vmark="4bea">而 Dario 也提前预测到，如果出现「技术不会向前发展」的信念，资本化不足，AI 进步就将停止。</p><h2 data-vmark="d58b">逐级扒皮 Llama 4</h2><p data-vmark="a667">最近闹出大丑闻的 Llama 4，已经证明了这一点。</p><p data-vmark="7821" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/e470456f-7060-45d3-bfb9-86750bfbbdd6.png?x-bce-process=image/format,f_auto" w="1080" h="595" data-weibo="3" data-type="png" data-vmark="a615"></p><p data-vmark="b670">我们很难说，Llama 4 系列三款模型中的两款代表了多少进展，显然在这个系列的发布中，夸大宣传的水分要比诚实的分析多得多。</p><h3 data-vmark="9a15">疑点 1：长上下文大海捞针，其实是骗人？</h3><p data-vmark="a745">Llama 拥有所谓业界领先的一千万个 token 的上下文窗口，听起来似乎很酷炫。</p><p data-vmark="64e1">可是等等，24 年 2 月，Gemini 1.5 Pro 的模型，就已经达到 1000 万 token 的上下文了！</p><p data-vmark="5e8a">在极端情况下，它可以在视频、音频和共同文本上，执行惊人的大海捞针任务，或许，是谷歌忽然意识到，大海捞针任务意义非常重大。</p><p data-vmark="6370">正如这篇 Llama 4 博客所说，如果把所有哈利波特的书都放进去，模型都能检索到放入其中的一个密码。</p><p data-vmark="169b" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/82b6c0a8-2301-431e-a97e-73b54652f0b3.png?x-bce-process=image/format,f_auto" w="1080" h="559" data-weibo="4" data-type="png" data-vmark="cce0"></p><p data-vmark="8649">不过，这位 CEO 表示，这些 48h 前发布的结果，不如 24 小时前更新的这个 fiction livebench 基准测试这么重要。</p><p data-vmark="5913">这个基准测试，用于长上下文的深度理解，LLM 必须将数万或数十万个 token 或单词拼凑在一起。</p><p data-vmark="116e">在这里，在这个基准测试中，Gemini 2.5 Pro 的表现非常好，而相比之下，Llama 4 的中等模型和小模型，性能极其糟糕。</p><p data-vmark="4526">而且随着 token 长度的增加，它们的表现越来越差。</p><p data-vmark="e829" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/42c6e3f0-08f7-43f9-82d8-02b916463475.png?x-bce-process=image/format,f_auto" w="1080" h="1061" data-weibo="5" data-type="png" data-vmark="97cb"></p><h3 data-vmark="31e0">疑点 2：为何周六发布？</h3><p data-vmark="9f2f"><strong>这位 CEO 察觉到的第二大疑点就在于，Llama 4 为何选在周六发布？</strong></p><p data-vmark="e8be">在整个美国 AI 技术圈里，这个发布日期都是史无前例的。</p><p data-vmark="49b3">如果阴谋论一点想，之所以选在周六发布，是因为 Meta 自己也心虚了，希望尽量减少人们的注意力。</p><p data-vmark="d0e6">此外，Llama 4 的最新训练数据截止时间是 2024 年 8 月，这就很奇怪。</p><p data-vmark="678d">要知道，Gemini 2.5 的训练知识截止时间是 2025 年 1 月。</p><p data-vmark="259d">这就意味着，在过去的 9 个月里，Meta 一直在使尽浑身解数，拼命让这个模型达到标准。</p><p data-vmark="404e">有一种可能性是，或许他们本打算早点发布 Llama 4，但就在 9 月，OpenAI 推出了 o 系列模型，今年 1 月，DeepSeek R1 又来了，所以 Meta 的所有计划都被打乱了。</p><p data-vmark="44c4" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/ea909d07-242b-48a0-8a3e-6ad387f166f1.png?x-bce-process=image/format,f_auto" w="1080" h="921" data-weibo="6" data-type="png" data-vmark="f49d"></p><h3 data-vmark="3612">疑点 3：大模型竞技场，究竟有没有作弊？</h3><p data-vmark="2ff9">不过，这位 CEO 也承认，尽管全网充斥着对 Llama 4 群嘲的声音，但它的确也展示出了一些坚实的进展。</p><p data-vmark="02b6" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/79ef3bb7-9ad6-4529-9f75-86fa0142bcf1.png?x-bce-process=image/format,f_auto" w="1047" h="1046" data-weibo="7" data-type="png" data-vmark="edff"></p><p data-vmark="ad24">比如 Llama 4 Maverick 的活动参数量大概只有 DeepSeek V3 的一半，却取得了相当的性能。</p><p data-vmark="1fa4" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/8dac5468-c9a0-4313-9cd0-f3c6ff059067.png?x-bce-process=image/format,f_auto" w="1080" h="923" data-weibo="8" data-type="png" data-vmark="266d"></p><p data-vmark="f72f">那现在的核心问题就在于，Meta 究竟有没有在 LM Arena 上进行作弊，在测试集上进行训练？</p><p data-vmark="cbe7">目前，LM Arena 已经迅速滑跪，公开了 2000 多组对战数据给公众检阅，并且表示会重新评估排行榜。</p><p data-vmark="309c" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/ce700d35-473f-4473-b702-c53e2361aea9.png?x-bce-process=image/format,f_auto" w="1080" h="967" data-type="png" data-vmark="eb54"></p><p data-vmark="edd9">目前姑且按照没有算，那就意味着我们拥有一个强大得惊人的基础模型了。</p><p data-vmark="8d7c" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/5bffb071-fcf9-4abf-ad68-6a3f37e05756.png?x-bce-process=image/format,f_auto" w="1080" h="590" data-type="png" data-vmark="16f7"></p><p data-vmark="4935" style="text-align: left;">看看这些真实数字，假设没有任何答案进入 Llama 4 的训练数据，这个模型在 GPQA Diamond 上的性能（谷歌验证的极其严格的 STEM 基准测试）实际上是比 DeepSeek V3 更好的。</p><p data-vmark="c9d1">而在这个基础上，Meta 就完全可以创建一个 SOTA 级别的思维模型。</p><p data-vmark="1d91">唯一的问题是，Gemini 2.5 Pro 已经存在了，而 DeepSeek R2 也随时会问世。</p><h3 data-vmark="9d28">疑点 4：代码很差</h3><p data-vmark="e17c">还有一点，当 Llama 4 走出舒适区时，性能就会开始狂降。</p><p data-vmark="8a5e">以 ADA 的 Polyglot 这个编码基准测试为例，它测验了一些系列编程语言的性能。</p><p data-vmark="d9b6">但与许多基准不同，它不仅仅关注 Python，而是一系列编程语言，现在依然是 Gemini 2.5 Pro 名列前茅。</p><p data-vmark="1556">但是想要找到 Llama 4 Maverick，可就很难了，得把鼠标滚动很久。</p><p data-vmark="fd18">它的得分当然惨不忍睹 —— 只有 15.6%。</p><p data-vmark="cfef" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/77af054e-df33-4530-ad6d-763e2a6e106b.gif" w="960" h="535" data-type="gif" data-advance="W3siVHlwZSI6IndlYnBhIiwiVXJsIjoiaHR0cHM6Ly9pbWcuaXRob21lLmNvbS9uZXdzdXBsb2FkZmlsZXMvMjAyNS80LzlkNzk0NzZiLTZkMDAtNGRjZS04ODA1LWYyZGQ0OWU4ZGJjNy53ZWJwIn1d" data-preview="https://img.ithome.com/newsuploadfiles/2025/4/77af054e-df33-4530-ad6d-763e2a6e106b.gif?x-bce-process=image/format,f_png" data-vmark="bcb6"></p><p data-vmark="f1ba">这就跟小扎的言论出入很大了，显得相当讽刺。</p><p data-vmark="2039">就在不久前，他还信誓旦旦地断定说，Meta 的 AI 模型将很快取代中级程序员。</p><p data-vmark="b23b" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/3085d7a1-0a21-474e-b475-b52a6907f459.png?x-bce-process=image/format,f_auto" w="1080" h="673" data-type="png" data-vmark="cf12"></p><h3 data-vmark="032a">疑点 5：「结果仅代表目前最好的内部运行」</h3><p data-vmark="2cde"><strong>这一点，同样已经在 AI 社区引发了群嘲。</strong></p><p data-vmark="f4fb">在下面这个表格中，Meta 将 Llama 4 和 Gemini2.0 Pro、GPT-4.5 等模型进行了比较，数字非常漂亮。</p><p data-vmark="8b02">但仔细看脚注，却说的是 Llama 模型的结果代表了目前最好的内部运行情况，所以很大可能是，Meta 把 Llama 4 跑了 5 遍或 10 遍，取了其中的最好结果。</p><p data-vmark="ec89" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/e840959d-1561-49ee-b370-748947514550.png?x-bce-process=image/format,f_auto" w="1080" h="525" data-type="png" data-vmark="a6b7"></p><p data-vmark="a939">而且，他们还故意不将 Llama 4 Behemoth 跟 DeepSeek V3 进行比较，后者比它在整体参数上小三倍，在互动参数上小八倍，性能却相似。</p><p data-vmark="23c6" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/b76f8e11-27bc-42e8-9379-929627da25c2.png?x-bce-process=image/format,f_auto" w="1080" h="517" data-type="png" data-vmark="a32d"></p><p data-vmark="21fa">如果从消极的角度下判断，就可以说 Llama 4 最大的模型参数上 DeepSeek V3 基础模型的许多倍，性能却基本处于同一水平。</p><p data-vmark="50d9">还有在 Simple Bench 中，Llama 4 Maverick 的得分大概为 27.7%，跟 DeepSeek V3 处于同一水平，还低于 Claude 3.5 Sonnet 这类非思维模型。</p><p data-vmark="85df" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/e03e2b31-def7-4b29-9c54-2b06043bc3e7.png?x-bce-process=image/format,f_auto" w="1080" h="986" data-type="png" data-vmark="a931"></p><p data-vmark="0566">另外，这位 CEO 还在 Llama 4 的使用条款中发现了这么一条。</p><p data-vmark="2535">如果你在欧洲，仍然可以成为它的最终用户，但却没有权利在它的基础上进行构建模型。</p><p data-vmark="183f" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/1cc22b6d-ba22-4989-bdcc-a9d14970600e.png?x-bce-process=image/format,f_auto" w="1080" h="232" data-type="png" data-vmark="ebb5"></p><h2 data-vmark="f4c8">马库斯：Llama 4 的惨痛教训表明，Scaling 已经结束</h2><p data-vmark="b588">而 Llama 4 的惨淡表现，也让 NYU 教授马库斯写出长文，断言 Scaling 已经结束，LLM 仍然无法推理。</p><p data-vmark="6d85" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/b1f8beca-a467-4f4c-b908-2328d435d14e.png?x-bce-process=image/format,f_auto" w="1080" h="308" data-type="png" data-vmark="5886"></p><p data-vmark="9a38">他的主要观点如下。</p><p data-vmark="a929">大模型的 Scaling 已经彻底结束了，这证实了我三年前在《深度学习正在撞墙》中的预测。</p><p data-vmark="f149">一位 AI 博士这样写道：Llama 4 的发布已经证实，即使 30 万亿 token 和 2 万亿参数，也不能让非推理模型比小型推理模型更好。</p><p data-vmark="d6fc" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/dd968b2c-9fed-4b17-b710-6f2ecc04f028.png?x-bce-process=image/format,f_auto" w="1080" h="813" data-type="png" data-vmark="5522"></p><p data-vmark="d1c9">规模化并不奏效，真正的智能需要的是意图，而意图需要远见，这都不是 AI 能做到的。</p><p data-vmark="4454" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/0e6b1ca6-6b7f-4f58-9da6-19844ee973fa.png?x-bce-process=image/format,f_auto" w="1080" h="375" data-type="png" data-vmark="3466"></p><p data-vmark="7d3c">即使 LLM 偶尔能提供正确的答案，往往也是通过模式识别或启发式的捷径，而非真正的数学推理。</p><p data-vmark="a10f">比如最近 ETU 团队关于 LLM 在美国奥数上糟糕表现的研究，就彻底击碎了「LLM 会做数学题」这个神话。</p><p data-vmark="9371" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/c1061835-9347-4b06-9e4e-f1d6e410f2c4.png?x-bce-process=image/format,f_auto" w="1080" h="630" data-type="png" data-vmark="e989"></p><p data-vmark="1652">最终，生成式 AI 很可能会变成一个在经济回报上失败的产品。</p><p data-vmark="e600">泡沫可能真的要破灭了。英伟达在 2025 年的跌幅，就已经超过了三分之一。</p><p data-vmark="5ad5">而 Meta 的 Llama 4 的残酷真相，再次证实了马库斯在 2024 年 3 月预测 ——</p><p data-vmark="1a09">达到 GPT-5 级别的模型，将会非常困难。很多公司都会有类似模型，但没有护城河。随着价格战进一步升级，许多只会有微薄的利润。</p><p data-vmark="d672" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/fac42e21-20c0-4e3d-9760-de1b8237bda9.png?x-bce-process=image/format,f_auto" w="1080" h="450" data-type="png" data-vmark="350c"></p><p data-vmark="9fcf">最终，马库斯以这样的方式总结了自己的发言 —— 大语言模型绝对不是解决之道，我们需要一些更可靠的方法。Gary Marcus 正在寻找对开发更可靠替代方法有兴趣的投资者。</p><p data-vmark="d5fd">参考资料：</p><ul class="custom_reference list-paddingleft-1"><li class="list-undefined list-reference-paddingleft"><p data-vmark="f6af"><span class="link-text-start-with-http">https://www.youtube.com/watch</span>?v=wOBqh9JqCDY</p></li><li class="list-undefined list-reference-paddingleft"><p data-vmark="9712"><span class="link-text-start-with-http">https://garymarcus.substack.com/p/scaling-is-over-the-bubble-may-be</span></p></li></ul>