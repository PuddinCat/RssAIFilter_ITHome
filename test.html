<p data-vmark="c995">IT之家 4 月 14 日消息，IT之家从豆包大模型团队获悉，字节跳动最新思考模型 Seed-Thinking-v1.5 技术细节今日公开，该模型将于 4 月 17 日<strong>通过火山引擎开放接口</strong>供用户体验。</p><p data-vmark="18eb">该模型在数学、编程、科学推理等专业领域及创意写作等通用任务中表现突出，同时，模型采用 MoE 架构，总参数 200B，激活参数为 20B，具备显著的推理成本优势，单位推理成本相比 DeepSeek R1 降低 50%。</p><ul class=" list-paddingleft-2"><li><p data-vmark="7f57"><strong>技术报告链接：</strong><span class="no-auto-spacing"><span class="link-text-start-with-http">https://github.com/ByteDance-Seed/Seed-Thinking-v1.5</span></span></p></li></ul><h2 data-vmark="7eae">模型各方面具体表现：</h2><ul class=" list-paddingleft-2"><li><p data-vmark="371f" style="text-align: left;">专业领域：数学推理（AIME 2024 得分 86.7，追平 OpenAI o3-mini-high）、编程竞赛（Codeforces pass@8 达 55.0%，接近 Gemini 2.5 Pro）、科学推理（GPQA 得分 77.3%，接近 o3-mini-high），均达到或接近业界第一梯队水平。</p></li><li><p data-vmark="ff6a">通用任务：人类评估表现超 DeepSeek R1 8%，覆盖多场景需求。</p></li><li><p data-vmark="01b8">成本优势：单位推理成本相比 DeepSeek R1 降低 50%，实现性能与效率的平衡。</p></li></ul><p data-vmark="b442" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/1a1086ae-5531-4760-ad6e-fcc3c094004d.png?x-bce-process=image/format,f_auto" w="1080" h="632" data-weibo="0" data-vmark="729f"></p><h2 data-vmark="8aa1">数据体系：融合可验证与创意性数据</h2><p data-vmark="836f">针对推理与生成任务的不同需求，团队优化了数据处理策略：</p><ul class=" list-paddingleft-2"><li><p data-vmark="9356"><strong>可验证数据</strong>（如数学、代码题）：通过百万级数据三重清洗（人工筛选 → 模型过滤 → 多模型验证），保留 10 万道高难度题目；设计答案整数化改造、离线沙箱验证等机制，确保模型输出真实推理过程；</p></li><li><p data-vmark="e2e6"><strong>非可验证数据</strong>（如创意写作）：基于豆包 1.5 Pro 训练集，剔除低价值样本，采用两两对比奖励法，优化生成质量；</p></li><li><p data-vmark="af38"><strong>全新评测基准</strong>：构建了超难数学数据集 BeyondAIME（100 道无答案题干题目），解决现有测试区分度不足问题。</p></li></ul><h2 data-vmark="9095">奖励模型：双轨体系校准训练方向</h2><p data-vmark="2270">团队提出双轨奖励机制，兼顾“对错分明”与“见仁见智”任务：</p><ul class=" list-paddingleft-2"><li><p data-vmark="0ca8"><strong>可验证任务</strong>：开发了两代验证器（Seed-Verifier → Seed-Thinking-Verifier），从字符匹配升级为推理步骤逐行对比（训练 / 测试集准确率超 99%），杜绝模型“奖励欺骗”；</p></li><li><p data-vmark="aff5"><strong>非可验证任务</strong>：引入 pairwise 对比训练，通过千万次“AB 测试”，捕捉人类对创意、情感等的隐性偏好，避免“众口难调”；</p></li><li><p data-vmark="c26d"><strong>双轨融合</strong>：针对混合场景设计协调机制，硬指标（对错）与软偏好（优劣）互补，支撑全场景训练。</p></li></ul><h2 data-vmark="e8b4">训练方法：“监督精调 + 强化学习”双阶段优化</h2><p data-vmark="6666">Seed-Thinking-v1.5 采用“打基础 + 磨能力”的全链路训练：</p><ul class=" list-paddingleft-2"><li><p data-vmark="de06"><strong>监督</strong><strong>精调</strong><strong>（</strong><strong>SFT</strong><strong>）</strong>：基于 40 万高质量实例（30 万可验证 +10 万非可验证数据），结合人工与模型协同筛选，构建长思考链数据集，确保模型“像人类一样思考”；</p></li><li><p data-vmark="7589"><strong>强化学习</strong><strong>（</strong><strong>RL</strong><strong>）</strong>：通过三重数据引擎（可验证 / 通用 / 混合数据）、算法创新（价值预训练、解耦 GAE 等）以及在线数据适配技术，解决训练不稳定、长链推理断层等问题，动态调整数据分布以保持最佳训练状态。</p></li></ul><h2 data-vmark="d713">训练框架：支撑 20B MoE 的底层架构</h2><p data-vmark="fafd">为应对&nbsp;20B&nbsp;MoE（总参数 200B）的复杂训练需求，团队优化了底层架构：</p><ul class=" list-paddingleft-2"><li><p data-vmark="7503"><strong>HybridFlow 编程模型</strong>：支持算法快速探索与分布式并行运行；</p></li><li><p data-vmark="8fc0"><strong>流式推理系统（</strong><strong>SRS</strong><strong>）</strong>：通过“流式推理”技术解耦模型演进与异步推理，将训练速度提升 3 倍，万亿参数下稳定性达 95%；</p></li><li><p data-vmark="c0b0"><strong>三层并行架构</strong>：结合张量 / 专家 / 序列并行，动态均衡负载，基于 KARP 算法优化 GPU 算力利用率。</p></li></ul>