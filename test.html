<p data-vmark="3cb0">IT之家 4 月 15 日消息，OpenAI 公司今天（4 月 15 日）发布博文，宣布以 API 的形式发布 GPT-4.1 系列模型，<strong>涵盖 GPT-4.1、GPT-4.1 mini 和 GPT-4.1 nano。</strong></p><p data-vmark="ddf0">这些模型在编程、指令遵循和长文本理解方面全面超越前代 GPT-4o 及 GPT-4o mini，上下文窗口最高支持 100 万 tokens，知识更新至 2024 年 6 月。</p><p data-vmark="a1b2" style="text-align: center;"><a class="ithome_super_player" contenteditable="false" target="_blank" href="https://weibo.com/tv/show/1034:5155575177347083?mid=5155575949688987"><img src="https://img.ithome.com/newsuploadfiles/2025/4/faf9f4e0-bf3a-42f6-9687-488b8b5cdadd.jpg?x-bce-process=image/format,f_auto" w="1440" h="810"></a></p><p data-vmark="3935">需要注意的是，该系列模型现阶段专为开发者打造，目前仅通过开发者 API 方式提供，普通用户暂时无法通过 ChatGPT 页面体验该模型。</p><p data-vmark="9ff6">OpenAI 表示在编程方面，相比较 GPT-4o 模型，GPT-4.1 模型的代码生成速度飙升 40%，且用户输入查询的成本降低了 80%。</p><p data-vmark="3d37" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/1c97a24b-e3cd-41e8-85dc-a83db0d51ca6.jpg?x-bce-process=image/format,f_auto" w="1250" h="750" data-weibo="1" data-vmark="3fdb" class="no-alt-img"></p><p data-vmark="fccb"><strong>新模型性能</strong></p><p data-vmark="a826">OpenAI 在官方博文中表示，GPT-4.1 系列模型在编程、指令遵循和长文本处理上表现优异，全面超越 GPT-4o 及 GPT-4o mini。</p><p data-vmark="6918">GPT-4.1 在编程测试 SWE-bench Verified 中得分 54.6%，较 GPT-4o 提升 21.4 个百分点，在指令遵循测试 MultiChallenge 中提升 10.5 个百分点，在多模态长文本测试 Video-MME 中创下 72.0% 的新纪录。</p><p data-vmark="2365">GPT-4.1 mini 和 nano 展现了小型模型的巨大潜力。GPT-4.1 mini 在多项基准测试中媲美甚至超越 GPT-4o，延迟降低近一半，成本减少 83%。</p><p data-vmark="dec3" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/4c0783ca-e177-404b-b354-84b2f32e3259.jpg?x-bce-process=image/format,f_auto" w="1440" h="1441" data-weibo="2" data-marks="1931fd9d012eb6d14c7118f7795fd76f67f961da8e018e6c81c2f3cd01d767b5bcf66619b8baad28bff7527d15815e6c" data-vmark="60e7" class="no-alt-img"></p><p data-vmark="6d5b" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/6bb94455-a787-4475-b39b-67984573b36c.jpg?x-bce-process=image/format,f_auto" w="1440" h="1220" data-weibo="3" data-marks="1931fd9d012eb6d1c2229b7a1c0b062fd96f3607f1e3660b273d631b4be39a3e703339528cdb5d2e1890543d9ab18abf" data-vmark="f141" class="no-alt-img"></p><p data-vmark="e7a0" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/aa71e9d2-4cf2-49a1-922d-01b514156c69.jpg?x-bce-process=image/format,f_auto" w="1440" h="2015" data-weibo="4"  data-vmark="064a" class="no-alt-img"></p><p data-vmark="b841">GPT-4.1 nano 作为最快、最经济的选择，拥有 100 万个 token 的上下文窗口，在 MMLU 测试中得分 80.1%，适合分类和自动补全任务。</p><p data-vmark="ca41">这些模型通过优化推理栈和提示缓存技术，显著降低了首次响应时间，为开发者提供高效低成本的解决方案。</p><p data-vmark="2278">GPT-4.1 系列模型在实际应用中表现突出，特别适合构建智能代理，处理复杂任务。例如，Windsurf 测试显示，GPT-4.1 在编程效率上提升 30%，减少 50% 不必要编辑；Thomson Reuters 的法律 AI 助手 CoCounsel 使用 GPT-4.1 后，多文档审查准确率提升 17%。</p><p data-vmark="6322"><strong>命名混乱引发关注</strong></p><p data-vmark="090a">GPT-4.1 的发布加剧了 OpenAI 产品命名的复杂性。</p><p data-vmark="88a4">ChatGPT 目前已包含 GPT-4o、GPT-4o mini、o1-pro 等多种模型选项。OpenAI 首席执行官山姆・奥尔特曼（Sam Altman）早在 2024 年 2 月就承认命名问题。</p><p data-vmark="3afc">他在 X 平台表示，产品线过于繁杂，计划通过未来的 GPT-5 整合品牌，OpenAI 计划在 2025 年 7 月前逐步淘汰 API 中的 GPT-4.5 Preview 模型，从而缓解命名混乱。</p><p data-vmark="5e8b">这一临时模型于 2024 年 2 月推出，曾被批评为“失败品”，开发者需在 2025 年 7 月前迁移到其他模型，不过，GPT-4.5 在 ChatGPT 中暂时保留，未受影响。</p><p data-vmark="1688"><strong>费用</strong></p><p data-vmark="0787">API&nbsp;价格方面，OpenAI&nbsp;GPT-4.1&nbsp;模型每&nbsp; 100&nbsp;万&nbsp;tokens&nbsp;输入费用为 2 美元（IT之家注：现汇率约合 14.6 元人民币），每&nbsp; 100&nbsp;万&nbsp;tokens&nbsp;输出费用为 8 美元（现汇率约合 58.3 元人民币）。在中等查询中，相比较&nbsp;GPT-4o，GPT-4.1&nbsp;不仅能提供更强悍的性能，而且便宜 26%。</p><p data-vmark="c8b5" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/dd0dfee4-0656-4748-8487-0bc188380c79.jpg?x-bce-process=image/format,f_auto" w="1183" h="1152" data-weibo="5" data-vmark="d23d" class="no-alt-img"></p><p data-vmark="a473">此外，OpenAI&nbsp;GPT-4.1&nbsp;nano&nbsp;是&nbsp;OpenAI&nbsp;最便宜、最快的模型：</p><p data-vmark="166f" style="text-align: center;"><img src="https://img.ithome.com/newsuploadfiles/2025/4/7722e5ba-86e7-4ce8-bd54-b92f63b4a2e8.png?x-bce-process=image/format,f_auto" w="1440" h="1235" data-weibo="6" data-vmark="32ce" class="no-alt-img"></p>