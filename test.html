<p data-vmark="f9ca">IT之家 4 月 8 日消息，Meta 公司的一位高管出面澄清了一则关于公司新 AI 模型的不实传言。该传言声称 Meta 在其新推出的 Llama 4 Maverick 和 Llama 4 Scout 模型上存在不当行为，<strong>即通过在特定基准测试的“测试集”上进行训练来提升模型的测试表现，同时隐藏模型的不足之处。</strong></p><p style="text-align: center;" data-vmark="3ecc"><img src="https://img.ithome.com/newsuploadfiles/2025/4/79288946-7e94-4acc-9d94-4693fe8dd55a.jpg?x-bce-process=image/format,f_auto" w="1200" h="628" data-weibo="0" data-mpos="2,2" data-marks="1931fd9d012eb6d15bc007dd83e262f71da5771d550ecbba2b2e1294c937daedb5dac0fdd74a19e034acafb3b8d45df0" data-vmark="ca35" class="no-alt-img"></p><p data-vmark="3fed">Meta 公司生成式人工智能副总裁艾哈迈德・阿尔・达赫勒（Ahmad Al-Dahle）在社交平台 X 上发表声明称，<strong>这种说法“根本不属实”</strong>。</p><p data-vmark="c203">在人工智能领域，测试集是用于在模型训练完成后评估其性能的数据集合。<strong>如果在测试集上进行训练，可能会人为地提高模型的基准测试分数，从而使模型看起来比实际更强大。</strong></p><p style="text-align: center;" data-vmark="e081"><img src="https://img.ithome.com/newsuploadfiles/2025/4/62d32b29-edb9-42c4-a528-b89c158f05e2.jpg?x-bce-process=image/format,f_auto" w="898" h="1261" data-weibo="1" data-mpos="2,2"  data-vmark="269b" class="no-alt-img"></p><p data-vmark="73fc">值得一提的是，Maverick 和 Scout 在某些任务上的表现不佳，以及 Meta 选择使用未发布的实验版本 Maverick 来在基准测试平台 LM Arena 上获得更好成绩的决定，都为这一谣言提供了“燃料”。研究人员观察到，可公开下载的 Maverick 与在 LM Arena 上托管的模型在行为上存在显著差异。</p><p data-vmark="4ff3">阿尔・达赫勒承认，部分用户在使用不同云服务提供商提供的 Maverick 和 Scout 模型时，确实遇到了“质量参差不齐”的情况。他解释道：“由于我们在模型准备好后就立即发布了，我们预计需要几天时间才能让所有公开的实现版本都调整到位。我们将继续进行错误修复并与合作伙伴进行对接。”</p>